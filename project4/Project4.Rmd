---
title: "Project 4"
author: "Tyler Zender"
date: "11/27/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(dplyr)
library(ggplot2)
library(recommenderlab)
library(DT)
library(data.table)
library(reshape2)
library(hash)
library(tidyverse)
library(Matrix)
library(proxy)
```

## System I: Recommendation based on genres

```{r}
 myurl = "https://liangfgithub.github.io/MovieData/"


# use colClasses = 'NULL' to skip columns
ratings = read.csv(paste0(myurl, 'ratings.dat?raw=true'), 
                   sep = ':',
                   colClasses = c('integer', 'NULL'), 
                   header = FALSE)
colnames(ratings) = c('UserID', 'MovieID', 'Rating', 'Timestamp')
```


```{r}
movies = readLines(paste0(myurl, 'movies.dat?raw=true'))
movies = strsplit(movies, split = "::", fixed = TRUE, useBytes = TRUE)
movies = matrix(unlist(movies), ncol = 3, byrow = TRUE)
movies = data.frame(movies, stringsAsFactors = FALSE)
colnames(movies) = c('MovieID', 'Title', 'Genres')
movies$MovieID = as.integer(movies$MovieID)

# convert accented characters
movies$Title[73]
movies$Title = iconv(movies$Title, "latin1", "UTF-8")
movies$Title[73]

# extract year
movies$Year = as.numeric(unlist(
  lapply(movies$Title, function(x) substr(x, nchar(x)-4, nchar(x)-1))))
```


```{r}
users = read.csv(paste0(myurl, 'users.dat?raw=true'),
                 sep = ':', header = FALSE)
users = users[, -c(2,4,6,8)] # skip columns
colnames(users) = c('UserID', 'Gender', 'Age', 'Occupation', 'Zip-code')
```

## System I: Recommendation based on genres - Version 1: Naive Approach

A simple approach to recommending movies would be to average the individual's ratings on a per-genre basis. From this, we may select the genre with the highest rating given and suggest popular movies from that genre.

First, we need to collect information about all the different genre types

```{r}
genres_col = movies$Genres
distinct_genres = c()
for (i in 1:length(genres_col)) {
  single_genre_set = genres_col[i]
  split_genres = unlist(strsplit(single_genre_set, "|", fixed=TRUE))
  distinct_genres = union(split_genres, distinct_genres)
}
```

Next, we need to define our 'popular' movies for each genre. In this case, our definition will be movies with the highest ratings for each genre with a minimum of 5 ratings

```{r}
movies_ratings = left_join(movies, ratings, by = "MovieID")
movies_ratings = movies_ratings %>% group_by(MovieID) %>% filter(n() >= 5)
movies_avg_ratings = movies_ratings %>% group_by(MovieID) %>% summarise_at(vars(Rating), list(AvgRating = mean))
movies_avg_ratings = left_join(movies_avg_ratings, movies[,c("MovieID", "Genres")], by = "MovieID")
movies_avg_ratings = movies_avg_ratings %>% separate_rows(Genres, sep='\\|') %>% arrange(Genres, desc(AvgRating))
top_movies_per_genre = movies_avg_ratings %>% group_by(Genres) %>% slice_max(order_by = AvgRating, n = 5)
top_movies_per_genre = left_join(top_movies_per_genre, movies[,c("MovieID", "Title", "Year")], by = "MovieID")
```

We can then test this approach with a user's ratings. 

```{r}
ratings_user1 = ratings[which(ratings$UserID == 1),]
ratings_user1 = left_join(ratings_user1, movies, by = "MovieID")
ratings_user1 = ratings_user1 %>% separate_rows(Genres, sep='\\|') %>% group_by(Genres) %>% summarise_at(vars(Rating), list(AvgRating = mean)) %>% slice_max(order_by = AvgRating, n = 1)
top_genre_user1 = ratings_user1$Genres
```

In this case, we see that the top genre for this user is `top_genre_user1`. We then suggest the following top 5 most popular movies for this genre:

```{r}
top_movies_per_genre %>% filter(Genres == top_genre_user1)
```

## System I: Recommendation based on genres - Version 2: User-Normalized Ratings

The previous naive approach for recommendations, though somewhat effective, works on the assumption that all individuals give ratings on the same scale. That is to say, individuals who enjoy a movie or genre to an identical degree would both give the same exact rating. However, this is often not the case. Individuals may often give a more skewed set of ratings for all movies they have seen. Because of this fact, it can be beneficial to normalize the set of ratings for users to ensure the composition of all ratings is more reliable.


```{r}
movies_ratings = left_join(movies, ratings, by = "MovieID")
movies_ratings = movies_ratings %>% filter(!is.na(UserID)) 
movies_ratings_avgs = movies_ratings %>% group_by(UserID) %>% summarise_at(vars(Rating), list(AvgRating = mean))
movies_ratings = left_join(movies_ratings, movies_ratings_avgs, by = "UserID")
movies_ratings = movies_ratings %>% mutate(NormalizedRating = Rating-AvgRating)
```

At this point, we now have a set of ratings that are normalized with respect to the individual's mean rating value.

```{r}
movies_ratings = movies_ratings %>% group_by(MovieID) %>% filter(n() >= 5)
movies_avg_ratings = movies_ratings %>% group_by(MovieID) %>% summarise_at(vars(NormalizedRating), list(AvgRating = mean))
movies_avg_ratings = left_join(movies_avg_ratings, movies[,c("MovieID", "Genres")], by = "MovieID")
movies_avg_ratings = movies_avg_ratings %>% separate_rows(Genres, sep='\\|') %>% arrange(Genres, desc(AvgRating))
top_movies_per_genre = movies_avg_ratings %>% group_by(Genres) %>% slice_max(order_by = AvgRating, n = 5)
top_movies_per_genre = left_join(top_movies_per_genre, movies[,c("MovieID", "Title", "Year")], by = "MovieID")
```

We can then test this approach with a user's ratings. 

```{r}
ratings_user1 = ratings[which(ratings$UserID == 1),]
ratings_user1 = left_join(ratings_user1, movies, by = "MovieID")
ratings_user1 = ratings_user1 %>% separate_rows(Genres, sep='\\|') %>% group_by(Genres) %>% summarise_at(vars(Rating), list(AvgRating = mean)) %>% slice_max(order_by = AvgRating, n = 1)
top_genre_user1 = ratings_user1$Genres
```

In this case, we see that the top genre for this user is `top_genre_user1`. We then suggest the following top 5 most popular movies for this genre:

```{r}
top_movies_per_genre %>% filter(Genres == top_genre_user1)
```

## System II: UBCF

```{r}

library(recommenderlab)
myurl = "https://liangfgithub.github.io/MovieData/"
ratings = read.csv(paste0(myurl, 'ratings.dat?raw=true'), 
                   sep = ':',
                   colClasses = c('integer', 'NULL'), 
                   header = FALSE)
colnames(ratings) = c('UserID', 'MovieID', 'Rating', 'Timestamp')
i = paste0('u', ratings$UserID)
j = paste0('m', ratings$MovieID)
x = ratings$Rating
tmp = data.frame(i, j, x, stringsAsFactors = T)
Rmat = sparseMatrix(as.integer(tmp$i), as.integer(tmp$j), x = tmp$x)
rownames(Rmat) = levels(tmp$i)
colnames(Rmat) = levels(tmp$j)
Rmat = new('realRatingMatrix', data = Rmat)

train = Rmat[1:500, ]
test = Rmat[501, ]
```

```{r}
mytrain = train
mytest = test

# Step 1: Normalize both the train and test datasets
mytrain = normalize(mytrain, method="center", row=TRUE)
test_mean = rowMeans(mytest)
mytest = normalize(mytest, method="center", row=TRUE)

# Step 2: Similarity
sim = similarity(mytrain, mytest, method = 'cosine', which = "users")

# Step 3: Top 20
top_20_similarity_values = tail(sort(sim),20)
top_20_lower_bound = top_20_similarity_values[1]
top_20_by_similarity_indexes = which(sim >= top_20_lower_bound)

# Step 4: Compute weighted average
top_20_similar_users_ratings = mytrain[top_20_by_similarity_indexes]
weights_vec = as(sim[top_20_by_similarity_indexes], "matrix")
weights = matrix(weights_vec, nrow=20, ncol=3706)
top_20_similar_users_ratings_weighted = as(top_20_similar_users_ratings, "matrix")*weights
#View(weights)
#View(as(top_20_similar_users_ratings, "matrix"))
#View(as(top_20_similar_users_ratings_weighted, "matrix"))
mysums = colSums(is.na(top_20_similar_users_ratings_weighted))
na_idxs = which(mysums == 20)
weights_nas_removed = weights
weights_nas_removed[is.na(top_20_similar_users_ratings_weighted)] = NA
averaged_ratings_for_top_20_similar_users = colSums(top_20_similar_users_ratings_weighted, na.rm = TRUE)/colSums(weights_nas_removed, na.rm = TRUE)
averaged_ratings_for_top_20_similar_users[na_idxs] = NA 

# Step 5: Replace with NAs
tmp.y = as.vector(as(mytest, "matrix"))
ind.y = which(!is.na(tmp.y))
averaged_ratings_for_top_20_similar_users[ind.y] = NA
averaged_ratings_for_top_20_similar_users = averaged_ratings_for_top_20_similar_users + test_mean
mypred = averaged_ratings_for_top_20_similar_users
```

```{r}
recommender.UBCF <- Recommender(train, method = "UBCF",
                                parameter = list(normalize = 'center', 
                                                 method = 'Cosine', 
                                                 nn = 20))

p.UBCF <- predict(recommender.UBCF, test, type="ratings")
p.UBCF <- as.numeric(as(p.UBCF, "matrix"))

sum(is.na(p.UBCF) != is.na(mypred)) ### should be zero
max(abs(p.UBCF - mypred), na.rm = TRUE)  ### should be less than 1e-06 
```

## System II: IBCF

```{r}

library(recommenderlab)
myurl = "https://liangfgithub.github.io/MovieData/"
ratings = read.csv(paste0(myurl, 'ratings.dat?raw=true'), 
                   sep = ':',
                   colClasses = c('integer', 'NULL'), 
                   header = FALSE)
colnames(ratings) = c('UserID', 'MovieID', 'Rating', 'Timestamp')
i = paste0('u', ratings$UserID)
j = paste0('m', ratings$MovieID)
x = ratings$Rating
tmp = data.frame(i, j, x, stringsAsFactors = T)
Rmat = sparseMatrix(as.integer(tmp$i), as.integer(tmp$j), x = tmp$x)
rownames(Rmat) = levels(tmp$i)
colnames(Rmat) = levels(tmp$j)
Rmat = new('realRatingMatrix', data = Rmat)

train = Rmat[1:500, ]
test = Rmat[501, ]
```


```{r}

options(digits=10)


mytrain = train
mytest = test

# Step 1: Normalize both the train and test datasets
mytrain = normalize(mytrain, method="center", row=TRUE)
test_mean = rowMeans(mytest)
mytest = normalize(mytest, method="center", row=TRUE)

# Step 2: Similarity
sim_mat = matrix(NA, 3706, 3706)
#sim = as(similarity(mytrain, method = 'cosine', which = "items"), "matrix")
#sim1 = proxy::simil(as(mytrain, "matrix"), method = "cosine", which = "items")
sim1 = proxy::simil(as(mytrain, "matrix"), by_rows = FALSE, method = "cosine")
sim1 = (1 + sim1)/2
sim=as(sim1, "matrix")
for (i in 1:3706)
{
  tmp.x = as.vector(sim[i, ])
  tmp.x[is.na(tmp.x)] = 0
  top_30_similarity_values = tail(sort(tmp.x),30)
  top_30_lower_bound = top_30_similarity_values[1]
  top_30_by_similarity_indexes = which(tmp.x >= top_30_lower_bound)
  sim_mat[i,top_30_by_similarity_indexes] = tmp.x[top_30_by_similarity_indexes]
}

# Step 3: Predict
tmp.y = as.vector(as(mytest, "matrix"))
mypred = rep(NA, length(tmp.y))
for (i in 1:length(tmp.y))
{
  if (is.na(tmp.y[i]))
  {
    current_movie_sim = sim_mat[i,]
    
    sim_mult_rating = tmp.y*current_movie_sim
    non_null_sims = sim_mult_rating/tmp.y
    mypred[i] = sum(sim_mult_rating, na.rm = TRUE)/sum(non_null_sims, na.rm = TRUE)
  }
}

# Step 4: Add back mean for the test user
mypred = mypred + test_mean

```

```{r}
recommender.IBCF <- Recommender(train, method = "IBCF",
                                parameter = list(normalize = 'center', 
                                                 method = 'Cosine', 
                                                 k = 30))

p.IBCF <- predict(recommender.IBCF, test, type="ratings")
p.IBCF <- as.numeric(as(p.IBCF, "matrix"))

## first output: should be less than 10
sum(is.na(p.IBCF) != is.na(mypred))  

## second output: should be less than 10%
mydiff = abs(p.IBCF - mypred)
sum(mydiff[!is.na(mydiff)] > 1e-6) / sum(!is.na(mydiff)) 
```
